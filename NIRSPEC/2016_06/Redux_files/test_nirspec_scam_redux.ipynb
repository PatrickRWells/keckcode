{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ccdredux as ccd\n",
    "import imfuncs as imf\n",
    "from astropy.io import fits as pf\n",
    "from scipy.ndimage import filters\n",
    "import shutil\n",
    "from math import fabs\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Define a function to create a temporary sky frame from\n",
    "three input frames\n",
    "\"\"\"\n",
    "\n",
    "def makesky_3(infiles, medians, indices, doquad=False, xcent=127, ycent=127):\n",
    "    \"\"\" \n",
    "    Makes a temporary sky file from 3 input files.\n",
    "    The default behavior treats the whole image together.  However, the NIRSPEC SCAM\n",
    "     appears to be read out by 4 amplifiers.  Thus, it may be better to treat the\n",
    "     four quadrants independently.  If that is the case, then set doquad=True.\n",
    "     NOTE: xcent and ycent represent the lower left pixel of the four pixels\n",
    "     that make up the \"four corners\" area (where the four regions\n",
    "     covered by the four different amps all touch).\n",
    "     NOTE: QUADRANT SKY CREATION NOT YET IMPLEMENTED\n",
    "    \"\"\"\n",
    "    x1 = np.array([0, 128, 0, 128])\n",
    "    x2 = x1+127\n",
    "    y1 = np.array([0, 0, 128, 128])\n",
    "    y2 = y1+127\n",
    "    tmpdat = pf.getdata(infiles[indices[0]])\n",
    "    tmpshape = tmpdat.shape\n",
    "    tmpsky = np.zeros((3,tmpshape[0],tmpshape[1]))\n",
    "    for i in range(3):\n",
    "        #if doquad:\n",
    "        #    for j in range(4):\n",
    "        #        tmpsky[i,y1[j]:y2[j],x1[j]:x2[j]] = ...\n",
    "        tmpsky[i,:,:] = pf.getdata(infiles[indices[i]]) / medians[indices[i]]\n",
    "    outsky = np.median(tmpsky,axis=0)\n",
    "    del tmpdat,tmpsky\n",
    "    return outsky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "A function that makes copies of the raw data files that we can freely modify.\n",
    "Unfortunately, something is screwed up with the header in the raw files,\n",
    "so we are just going to copy over the data, which is non-optimal\n",
    "\"\"\"\n",
    "def get_raw(sciframes):\n",
    "    \"\"\" \n",
    "    Inputs:\n",
    "      sciframes - list or array containing the frame numbers associated with\n",
    "                  the observations of the desired object\n",
    "      lensroot  - rootname for output files\n",
    "    \"\"\"\n",
    "    rawdir = '../Raw_scam/'\n",
    "    rawroot = 'raw0'   \n",
    "    infiles = []\n",
    "    for i in sciframes:\n",
    "        rawname = '%s%s%03d.fits' % (rawdir,rawroot,i)\n",
    "        workname = 'work_%03d.fits' % i\n",
    "        infiles.append(workname)\n",
    "        shutil.copyfile(rawname,workname)\n",
    "        #data = pf.getdata(rawname,ignore_missing_end=True)\n",
    "        #pf.PrimaryHDU(data).writeto(workname)\n",
    "        #del data\n",
    "    return infiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['work_162.fits', 'work_163.fits', 'work_164.fits', 'work_165.fits', 'work_166.fits', 'work_167.fits', 'work_168.fits', 'work_169.fits', 'work_170.fits']\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Get the raw data (modify for each lens-filter combination) \"\"\"\n",
    "sciframes = np.arange(162,171) # For J1756 J-band\n",
    "lensroot = 'J1756_J'\n",
    "infiles = get_raw(sciframes)\n",
    "print ''\n",
    "print infiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median_combine: Inputs:\n",
      "-----------------------\n",
      "  bias frame: [No bias file]\n",
      "\n",
      "median_combine: Loading files\n",
      "-----------------------------\n",
      " work_162.fits\n",
      " work_163.fits\n",
      " work_164.fits\n",
      " work_165.fits\n",
      " work_166.fits\n",
      " work_167.fits\n",
      " work_168.fits\n",
      " work_169.fits\n",
      " work_170.fits\n",
      "\n",
      "median_combine: Getting info on first file\n",
      "------------------------------------------\n",
      "Filename: work_162.fits\n",
      "No.    Name         Type      Cards   Dimensions   Format\n",
      "0    PRIMARY     PrimaryHDU     143   (256, 256)   int32   \n",
      "\n",
      "median_combine: setting up stack for images (HDU 0)\n",
      "----------------------------------------------------\n",
      "Stack will have dimensions (9,256,256)\n",
      " work_162.fits\n",
      "    Normalizing work_162.fits by 8801.000000\n",
      " work_163.fits\n",
      "    Normalizing work_163.fits by 9056.000000\n",
      " work_164.fits\n",
      "    Normalizing work_164.fits by 8690.500000\n",
      " work_165.fits\n",
      "    Normalizing work_165.fits by 9608.000000\n",
      " work_166.fits\n",
      "    Normalizing work_166.fits by 10212.000000\n",
      " work_167.fits\n",
      "    Normalizing work_167.fits by 11339.000000\n",
      " work_168.fits\n",
      "    Normalizing work_168.fits by 15015.000000\n",
      " work_169.fits\n",
      "    Normalizing work_169.fits by 13976.000000\n",
      " work_170.fits\n",
      "    Normalizing work_170.fits by 14377.000000\n",
      "\n",
      "median_combine: Computing median frame (can take a while)...\n",
      "   ... Writing output to J1756_J_sky1.fits.\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Make the first sky frame \"\"\"\n",
    "skyname = '%s_sky1.fits' % lensroot\n",
    "ccd.median_combine(infiles,skyname,normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading file J1756_J_sky1.fits\n",
      "-----------------------------------------------\n",
      "Filename: J1756_J_sky1.fits\n",
      "No.    Name         Type      Cards   Dimensions   Format\n",
      "0    PRIMARY     PrimaryHDU       6   (256, 256)   float64   \n",
      "get_wcs: No valid WCS information in file header\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Use the sky frame to make an initial bad pixel mask and then\n",
    "update the sky frame itself to mask out the bad pixels.\n",
    "\"\"\"\n",
    "sky = imf.Image(skyname)\n",
    "\n",
    "\"\"\" \n",
    "Do a 3-sigma clipping on the data and use the resulting clipped\n",
    "mean and clipped rms to set the criterion for determining bad \n",
    "pixels\n",
    "\"\"\"\n",
    "sky.sigma_clip()\n",
    "diff = np.fabs((sky.hdu[0].data - sky.mean_clip) / sky.rms_clip)\n",
    "\n",
    "\"\"\" Create the bad pixel mask and write it out \"\"\"\n",
    "bpmask = np.fabs(diff)>5.\n",
    "tmp = bpmask.astype(int)\n",
    "maskname = '%s_mask_sky1.fits' % lensroot\n",
    "pf.PrimaryHDU(tmp).writeto(maskname,clobber=True)\n",
    "del tmp\n",
    "\n",
    "\"\"\" Replace the bad pixels with the median value in the image \"\"\"\n",
    "skydat = sky.hdu[0].data.copy()\n",
    "skymed = np.median(skydat)\n",
    "skydat[bpmask] = skymed\n",
    "\n",
    "\"\"\" Save the result \"\"\"\n",
    "sky1v2name = '%s_sky1_v2.fits' % lensroot\n",
    "pf.PrimaryHDU(skydat).writeto(sky1v2name,clobber=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Replace the bad pixels in the input files using a 2-step process:\n",
    "  1. Replace each of the bad pixels with the overall median value\n",
    "  2. WAIT FOR NOW ON THIS\n",
    "\n",
    "\"\"\"\n",
    "for i in infiles:\n",
    "    hdu = pf.open(i,mode='update')\n",
    "    data = hdu[0].data\n",
    "    datmed = np.median(data)\n",
    "    data[bpmask] = datmed\n",
    "    hdu.flush()\n",
    "    del(hdu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\" Do a running sky subtraction \"\"\"\n",
    "\n",
    "\"\"\" Start by reading in all the files and calculating their median values \"\"\"\n",
    "alldat = np.zeros((len(infiles),bpmask.shape[0],bpmask.shape[1]))\n",
    "allmed = np.zeros(len(infiles))\n",
    "index_list = []\n",
    "for i in range(len(infiles)):\n",
    "    tmp = pf.getdata(infiles[i])\n",
    "    allmed[i] = np.median(tmp)\n",
    "    if i==0:\n",
    "        index_list.append([0,1,2])\n",
    "    elif i==(len(infiles)-1):\n",
    "        index_list.append([i-2,i-1,i])\n",
    "    else:\n",
    "        index_list.append([i-1,i,i+1])\n",
    "for i in range(len(infiles)):\n",
    "    tmp = pf.getdata(infiles[i])\n",
    "    tmpsub = tmp - allmed[i] * makesky_3(infiles,allmed,index_list[i])\n",
    "    outname = 'tmpsub_%02d.fits' % sciframes[i]\n",
    "    pf.PrimaryHDU(tmpsub).writeto(outname,clobber=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote sky-subtracted image (pass 1) to sub1_229.fits\n",
      "Wrote sky-subtracted image (pass 1) to sub1_230.fits\n",
      "Wrote sky-subtracted image (pass 1) to sub1_231.fits\n",
      "Wrote sky-subtracted image (pass 1) to sub1_232.fits\n",
      "Wrote sky-subtracted image (pass 1) to sub1_233.fits\n",
      "Wrote sky-subtracted image (pass 1) to sub1_234.fits\n",
      "Wrote sky-subtracted image (pass 1) to sub1_235.fits\n",
      "Wrote sky-subtracted image (pass 1) to sub1_236.fits\n",
      "Wrote sky-subtracted image (pass 1) to sub1_237.fits\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Do the initial sky subtraction using the updated sky frame \"\"\"\n",
    "sky1 = pf.getdata(sky1v2name)\n",
    "skymed = np.median(sky1)\n",
    "for i in infiles:\n",
    "    scidat = pf.getdata(i).astype(float)\n",
    "    scimed = np.median(scidat)\n",
    "    scidat[bpmask] = scimed\n",
    "    scimed2 = np.median(scidat)\n",
    "    diff = scidat - (scimed2 / skymed) * sky1\n",
    "    outfile = i.replace('work','sub1')\n",
    "    pf.PrimaryHDU(diff).writeto(outfile)\n",
    "    print 'Wrote sky-subtracted image (pass 1) to %s' % outfile\n",
    "    del scidat,diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define a function that does a quick coadd of a list of input files given\n",
    "pixel offsets between them.  The quick-and-dirty aspect to this processing\n",
    "is that the function will just do integer pixel shifts.\n",
    "\"\"\"\n",
    "\n",
    "def quick_coadd(filelist, offsets, outfile):\n",
    "    \n",
    "    \"\"\" Start by shifting the offsets to be centered on the mean offset \"\"\"\n",
    "    dx = offsets[:,0] - (offsets[:,0].mean())\n",
    "    dy = offsets[:,1] - (offsets[:,1].mean())\n",
    "    dxrange = (dx.min(),dx.max())\n",
    "    dyrange = (dy.min(),dy.max())\n",
    "    \n",
    "    \"\"\" Make a blank image of the appropriate size \"\"\"\n",
    "    dat0 = pf.getdata(filelist[0])\n",
    "    xsize,ysize = dat0.shape[1],dat0.shape[0]\n",
    "    del dat0\n",
    "    outxsize = int(xsize + fabs(dxrange[0]) + fabs(dxrange[1]))\n",
    "    outysize = int(ysize + fabs(dyrange[0]) + fabs(dyrange[1]))\n",
    "    outim = np.zeros((outysize,outxsize))\n",
    "    \n",
    "    \"\"\" Insert the data with the appropriate offsets \"\"\"\n",
    "    x0 = fabs(dxrange[0])\n",
    "    y0 = fabs(dyrange[0])\n",
    "    x0 = dxrange[1]\n",
    "    y0 = dyrange[1]\n",
    "    x1 = (x0 - dx).astype(int)\n",
    "    x2 = x1 + int(xsize)\n",
    "    y1 = (y0 - dy).astype(int)\n",
    "    y2 = y1 + int(ysize)\n",
    "    print 'Output file will have size: %d x %d' % (outxsize,outysize)\n",
    "    print x0,y0\n",
    "    print dx,dy\n",
    "    print x1,x2\n",
    "    print y1,y2\n",
    "    for i in range(len(filelist)):\n",
    "        tmp = pf.getdata(filelist[i])\n",
    "        print i, tmp.shape\n",
    "        try:\n",
    "            outim[y1[i]:y2[i],x1[i]:x2[i]] += tmp\n",
    "        except:\n",
    "            print 'Failed on image %i (%s) with x1=%d,x2=%d,y1=%d,y2=%d' % (i,filelist[i],x1[i],x2[i],y1[i],y2[i])\n",
    "        del tmp\n",
    "    pf.PrimaryHDU(outim).writeto(outfile,clobber=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sub1_229.fits', 'sub1_230.fits', 'sub1_231.fits', 'sub1_232.fits', 'sub1_233.fits', 'sub1_234.fits', 'sub1_235.fits', 'sub1_236.fits', 'sub1_237.fits']\n",
      "F2214_Kp_coadd_quick.fits\n",
      "Output file will have size: 279 x 280\n",
      "11.7777777778 12.1111111111\n",
      "[ -0.22222222 -11.22222222  11.77777778 -11.22222222  -0.22222222\n",
      "  10.77777778 -11.22222222  11.77777778  -0.22222222] [  0.11111111  10.11111111   0.11111111 -10.88888889  12.11111111\n",
      " -10.88888889   0.11111111  11.11111111 -11.88888889]\n",
      "[12 23  0 23 12  1 23  0 12] [268 279 256 279 268 257 279 256 268]\n",
      "[12  2 12 23  0 23 12  1 24] [268 258 268 279 256 279 268 257 280]\n",
      "0 (256, 256)\n",
      "1 (256, 256)\n",
      "2 (256, 256)\n",
      "3 (256, 256)\n",
      "4 (256, 256)\n",
      "5 (256, 256)\n",
      "6 (256, 256)\n",
      "7 (256, 256)\n",
      "8 (256, 256)\n",
      "\n",
      "Wrote coadded file to F2214_Kp_coadd_quick.fits\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Do a quick-and-dirty coadd \"\"\"\n",
    "offsets = np.loadtxt('%s_offsets.txt' % lensroot)\n",
    "#offsets = np.loadtxt('J1618_Kp_offsets.txt')\n",
    "xshifts = -1. * (offsets[:,0] - offsets[0,0])\n",
    "yshifts = -1. * (offsets[:,1] - offsets[0,1])\n",
    "subfiles = []\n",
    "for i in infiles:\n",
    "    subfiles.append(i.replace('work','sub1'))\n",
    "print subfiles\n",
    "outfile = '%s_coadd_quick.fits' % lensroot\n",
    "print outfile\n",
    "quick_coadd(subfiles,offsets,outfile)\n",
    "#xshifts = offsets[:,0]\n",
    "#yshifts = offsets[:,1]\n",
    "#ccd.coadd_intshift(subfiles,xshifts,yshifts,outfile)\n",
    "print ''\n",
    "print 'Wrote coadded file to %s' % outfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
