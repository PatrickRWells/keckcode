{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ccdredux as ccd\n",
    "import imfuncs as imf\n",
    "from astropy.io import fits as pf\n",
    "from scipy.ndimage import filters\n",
    "import shutil\n",
    "from math import fabs\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Define a function to create a temporary sky frame from\n",
    "three input frames\n",
    "\"\"\"\n",
    "\n",
    "def makesky_3(infiles, medians, indices):\n",
    "    \"\"\" Makes a temporary sky file from 3 input files \"\"\"\n",
    "    \n",
    "    tmpdat = pf.getdata(infiles[indices[0]])\n",
    "    tmpshape = tmpdat.shape\n",
    "    tmpsky = np.zeros((3,tmpshape[0],tmpshape[1]))\n",
    "    for i in range(3):\n",
    "        tmpsky[i,:,:] = pf.getdata(infiles[indices[i]]) / medians[indices[i]]\n",
    "    outsky = np.median(tmpsky,axis=0)\n",
    "    del tmpdat,tmpsky\n",
    "    return outsky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define a function that does a quick coadd of a list of input files given\n",
    "pixel offsets between them.  The quick-and-dirty aspect to this processing\n",
    "is that the function will just do integer pixel shifts.\n",
    "\"\"\"\n",
    "\n",
    "def quick_coadd(filelist, offsets, outfile):\n",
    "    \n",
    "    \"\"\" Start by shifting the offsets to be centered on the mean offset \"\"\"\n",
    "    dx = offsets[:,0] - (offsets[:,0].mean())\n",
    "    dy = offsets[:,1] - (offsets[:,1].mean())\n",
    "    dxrange = (dx.min(),dx.max())\n",
    "    dyrange = (dy.min(),dy.min())\n",
    "    \n",
    "    \"\"\" Make a blank image of the appropriate size \"\"\"\n",
    "    dat0 = pf.getdata(filelist[0])\n",
    "    xsize,ysize = dat0.shape[1],dat0.shape[0]\n",
    "    del dat0\n",
    "    outxsize = int(xsize + fabs(dxrange[0]) + fabs(dxrange[1]))\n",
    "    outysize = int(ysize + fabs(dyrange[0]) + fabs(dyrange[1]))\n",
    "    outim = np.zeros((outysize,outxsize))\n",
    "    \n",
    "    \"\"\" Insert the data with the appropriate offsets \"\"\"\n",
    "    x0 = fabs(dxrange[0])\n",
    "    y0 = fabs(dyrange[0])\n",
    "    x1 = (x0 - dx).astype(int)\n",
    "    x2 = x1 + int(xsize)\n",
    "    y1 = (y0 - dy).astype(int)\n",
    "    y2 = y1 + int(ysize)\n",
    "    print x1,x2\n",
    "    print y1,y2\n",
    "    print x2 - x1\n",
    "    print y2 - y1\n",
    "    for i in range(len(filelist)):\n",
    "        tmp = pf.getdata(filelist[i])\n",
    "        print i, tmp.shape\n",
    "        try:\n",
    "            outim[y1[i]:y2[i],x1[i]:x2[i]] += tmp\n",
    "        except:\n",
    "            print 'Failed on image %i (%s) with x1=%d,x2=%d,y1=%d,y2=%d' % (i,filelist[i],x1[i],x2[i],y1[i],y2[i])\n",
    "        del tmp\n",
    "    pf.PrimaryHDU(outim).writeto(outfile,clobber=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['work_08.fits', 'work_09.fits', 'work_10.fits', 'work_11.fits', 'work_12.fits', 'work_13.fits', 'work_14.fits', 'work_15.fits', 'work_16.fits']\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Start by making copies of the raw data files that we can freely modify.\n",
    "Unfortunately, something is screwed up with the header in the raw files,\n",
    "so we are just going to copy over the data, which is non-optimal\n",
    "\"\"\"\n",
    "rawdir = '../Raw_scam/'\n",
    "rawroot = 'jun18i00'\n",
    "sciframes = np.arange(8,17)\n",
    "infiles = []\n",
    "for i in sciframes:\n",
    "    rawname = '%s%s%02d.fits' % (rawdir,rawroot,i)\n",
    "    workname = 'work_%02d.fits' % i\n",
    "    infiles.append(workname)\n",
    "    #shutil.copyfile(rawname,workname)\n",
    "    data = pf.getdata(rawname,ignore_missing_end=True)\n",
    "    pf.PrimaryHDU(data).writeto(workname)\n",
    "print ''\n",
    "print infiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: work_09.fits\n",
      "No.    Name         Type      Cards   Dimensions   Format\n",
      "0    PRIMARY     PrimaryHDU       6   (256, 256)   int32   \n"
     ]
    }
   ],
   "source": [
    "hdu = pf.open(infiles[1])\n",
    "hdu.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median_combine: Inputs:\n",
      "-----------------------\n",
      "  bias frame: [No bias file]\n",
      "\n",
      "median_combine: Loading files\n",
      "-----------------------------\n",
      " work_08.fits\n",
      " work_09.fits\n",
      " work_10.fits\n",
      " work_11.fits\n",
      " work_12.fits\n",
      " work_13.fits\n",
      " work_14.fits\n",
      " work_15.fits\n",
      " work_16.fits\n",
      "\n",
      "median_combine: Getting info on first file\n",
      "------------------------------------------\n",
      "Filename: work_08.fits\n",
      "No.    Name         Type      Cards   Dimensions   Format\n",
      "0    PRIMARY     PrimaryHDU       6   (256, 256)   int32   \n",
      "\n",
      "median_combine: setting up stack for images (HDU 0)\n",
      "----------------------------------------------------\n",
      "Stack will have dimensions (9,256,256)\n",
      " work_08.fits\n",
      "    Normalizing work_08.fits by 9757.000000\n",
      " work_09.fits\n",
      "    Normalizing work_09.fits by 12077.000000\n",
      " work_10.fits\n",
      "    Normalizing work_10.fits by 10949.500000\n",
      " work_11.fits\n",
      "    Normalizing work_11.fits by 10425.000000\n",
      " work_12.fits\n",
      "    Normalizing work_12.fits by 10154.000000\n",
      " work_13.fits\n",
      "    Normalizing work_13.fits by 10488.000000\n",
      " work_14.fits\n",
      "    Normalizing work_14.fits by 10009.000000\n",
      " work_15.fits\n",
      "    Normalizing work_15.fits by 9577.000000\n",
      " work_16.fits\n",
      "    Normalizing work_16.fits by 9199.000000\n",
      "\n",
      "median_combine: Computing median frame (can take a while)...\n",
      "   ... Writing output to sky1.fits.\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Make the first sky frame \"\"\"\n",
    "ccd.median_combine(infiles,'sky1.fits',normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading file sky1.fits\n",
      "-----------------------------------------------\n",
      "Filename: sky1.fits\n",
      "No.    Name         Type      Cards   Dimensions   Format\n",
      "0    PRIMARY     PrimaryHDU       6   (256, 256)   float64   \n",
      "get_wcs: No valid WCS information in file header\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Use the sky frame to make an initial bad pixel mask and then\n",
    "update the sky frame itself to mask out the bad pixels.\n",
    "\"\"\"\n",
    "sky = imf.Image('sky1.fits')\n",
    "\n",
    "\"\"\" \n",
    "Do a 3-sigma clipping on the data and use the resulting clipped\n",
    "mean and clipped rms to set the criterion for determining bad \n",
    "pixels\n",
    "\"\"\"\n",
    "sky.sigma_clip()\n",
    "diff = np.fabs((sky.hdu[0].data - sky.mean_clip) / sky.rms_clip)\n",
    "\n",
    "\"\"\" Create the bad pixel mask and write it out \"\"\"\n",
    "bpmask = diff>5.\n",
    "tmp = bpmask.astype(int)\n",
    "pf.PrimaryHDU(tmp).writeto('mask_sky1.fits')\n",
    "del tmp\n",
    "\n",
    "\"\"\" Replace the bad pixels with the median value in the image \"\"\"\n",
    "skydat = sky.hdu[0].data.copy()\n",
    "skymed = np.median(skydat)\n",
    "skydat[bpmask] = skymed\n",
    "\n",
    "\"\"\" Save the result \"\"\"\n",
    "pf.PrimaryHDU(skydat).writeto('sky1_v2.fits',clobber=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Replace the bad pixels in the input files using a 2-step process:\n",
    "  1. Replace each of the bad pixels with the overall median value\n",
    "  2. WAIT FOR NOW ON THIS\n",
    "\n",
    "\"\"\"\n",
    "for i in infiles:\n",
    "    hdu = pf.open(i,mode='update')\n",
    "    data = hdu[0].data\n",
    "    datmed = np.median(data)\n",
    "    data[bpmask] = datmed\n",
    "    hdu.flush()\n",
    "    del(hdu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\" Do a running sky subtraction \"\"\"\n",
    "\n",
    "\"\"\" Start by reading in all the files and calculating their median values \"\"\"\n",
    "alldat = np.zeros((len(infiles),bpmask.shape[0],bpmask.shape[1]))\n",
    "allmed = np.zeros(len(infiles))\n",
    "index_list = []\n",
    "for i in range(len(infiles)):\n",
    "    tmp = pf.getdata(infiles[i])\n",
    "    allmed[i] = np.median(tmp)\n",
    "    if i==0:\n",
    "        index_list.append([0,1,2])\n",
    "    elif i==(len(infiles)-1):\n",
    "        index_list.append([i-2,i-1,i])\n",
    "    else:\n",
    "        index_list.append([i-1,i,i+1])\n",
    "for i in range(len(infiles)):\n",
    "    tmp = pf.getdata(infiles[i])\n",
    "    tmpsub = tmp - allmed[i] * makesky_3(infiles,allmed,index_list[i])\n",
    "    outname = 'tmpsub_%02d.fits' % sciframes[i]\n",
    "    pf.PrimaryHDU(tmpsub).writeto(outname,clobber=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create an updated sky frame by:\n",
    "  1. Replacing the bad pixels in the sky frame with the median level of the image\n",
    "\"\"\"\n",
    "\n",
    "\"\"\" Replace the bad pixels with the median value in the image \"\"\"\n",
    "skydat = sky.hdu[0].data.copy()\n",
    "skymed = np.median(skydat)\n",
    "skydat[bpmask] = skymed\n",
    "\n",
    "\"\"\" Smooth by quadrant MAY BE A MISTAKE\"\"\"\n",
    "skysmo = np.ones(skydat.shape)\n",
    "x = [0, 0, 128, 128]\n",
    "y = [0, 128, 0, 128]\n",
    "quad = np.ones((4,128,128))\n",
    "for i in range(4):\n",
    "    x1 = x[i]\n",
    "    x2 = x1 + 128\n",
    "    y1 = y[i]\n",
    "    y2 = y1 + 128\n",
    "    tmp = skydat[y1:y2,x1:x2]\n",
    "    tmpsmo = filters.uniform_filter(tmp,3,cval=1.)\n",
    "    skysmo[y1:y2,x1:x2] = tmpsmo.copy()\n",
    "\n",
    "\"\"\" Save the result \"\"\"\n",
    "pf.PrimaryHDU(skydat).writeto('sky1_v2.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote sky-subtracted image (pass 1) to sub1_08.fits\n",
      "Wrote sky-subtracted image (pass 1) to sub1_09.fits\n",
      "Wrote sky-subtracted image (pass 1) to sub1_10.fits\n",
      "Wrote sky-subtracted image (pass 1) to sub1_11.fits\n",
      "Wrote sky-subtracted image (pass 1) to sub1_12.fits\n",
      "Wrote sky-subtracted image (pass 1) to sub1_13.fits\n",
      "Wrote sky-subtracted image (pass 1) to sub1_14.fits\n",
      "Wrote sky-subtracted image (pass 1) to sub1_15.fits\n",
      "Wrote sky-subtracted image (pass 1) to sub1_16.fits\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ff1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-a82c2f1ae466>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m'Wrote sky-subtracted image (pass 1) to %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mscidat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mff1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ff1' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\" Do the initial sky subtraction using the updated sky frame \"\"\"\n",
    "sky1 = pf.getdata('sky1_v2.fits')\n",
    "skymed = np.median(sky1)\n",
    "for i in infiles:\n",
    "    scidat = pf.getdata(i).astype(float)\n",
    "    scimed = np.median(scidat)\n",
    "    scidat[bpmask] = scimed\n",
    "    scimed2 = np.median(scidat)\n",
    "    diff = scidat - (scimed2 / skymed) * sky1\n",
    "    outfile = i.replace('work','sub1')\n",
    "    pf.PrimaryHDU(diff).writeto(outfile)\n",
    "    print 'Wrote sky-subtracted image (pass 1) to %s' % outfile\n",
    "    del scidat,diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24 46  0 46 23  0 45  0 23] [280 302 256 302 279 256 301 256 279]\n",
      "[22  0 22 44  0 44 21  0 44] [278 256 278 300 256 300 277 256 300]\n",
      "[256 256 256 256 256 256 256 256 256]\n",
      "[256 256 256 256 256 256 256 256 256]\n",
      "0 (256, 256)\n",
      "1 (256, 256)\n",
      "2 (256, 256)\n",
      "3 (256, 256)\n",
      "4 (256, 256)\n",
      "5 (256, 256)\n",
      "6 (256, 256)\n",
      "7 (256, 256)\n",
      "8 (256, 256)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Do a quick-and-dirty coadd \"\"\"\n",
    "offsets = np.loadtxt('pos_for_offsets.txt')\n",
    "subfiles = glob.glob('sub1*fits')\n",
    "quick_coadd(subfiles,offsets,'foo.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
